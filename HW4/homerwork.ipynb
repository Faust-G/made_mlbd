{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:53:34.851093Z","iopub.execute_input":"2022-12-12T07:53:34.851497Z","iopub.status.idle":"2022-12-12T07:53:46.226996Z","shell.execute_reply.started":"2022-12-12T07:53:34.851459Z","shell.execute_reply":"2022-12-12T07:53:46.225344Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /opt/conda/lib/python3.7/site-packages (3.3.1)\nRequirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.7/site-packages (from pyspark) (0.10.9.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nimport pyspark.sql.types as T\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\nfrom pyspark.ml.feature import Word2Vec","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:53:46.228841Z","iopub.execute_input":"2022-12-12T07:53:46.229257Z","iopub.status.idle":"2022-12-12T07:53:46.991351Z","shell.execute_reply.started":"2022-12-12T07:53:46.229216Z","shell.execute_reply":"2022-12-12T07:53:46.990030Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:53:46.993708Z","iopub.execute_input":"2022-12-12T07:53:46.994076Z","iopub.status.idle":"2022-12-12T07:53:48.992733Z","shell.execute_reply.started":"2022-12-12T07:53:46.994044Z","shell.execute_reply":"2022-12-12T07:53:48.991300Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n  inflating: train.csv               \n","output_type":"stream"}]},{"cell_type":"code","source":"spark = SparkSession.builder.master(\"local[5]\").appName(\"NLP\").getOrCreate()\nspark.sparkContext.setLogLevel('ERROR')","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:54:30.299273Z","iopub.execute_input":"2022-12-12T07:54:30.300663Z","iopub.status.idle":"2022-12-12T07:54:36.205927Z","shell.execute_reply.started":"2022-12-12T07:54:30.300603Z","shell.execute_reply":"2022-12-12T07:54:36.204300Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"22/12/12 07:54:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/working/train.csv\")\ndata.fillna(\"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:54:36.210153Z","iopub.execute_input":"2022-12-12T07:54:36.211023Z","iopub.status.idle":"2022-12-12T07:54:37.432930Z","shell.execute_reply.started":"2022-12-12T07:54:36.210965Z","shell.execute_reply":"2022-12-12T07:54:37.431710Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_train, data_test = train_test_split(data, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:54:37.434383Z","iopub.execute_input":"2022-12-12T07:54:37.435331Z","iopub.status.idle":"2022-12-12T07:54:37.513099Z","shell.execute_reply.started":"2022-12-12T07:54:37.435291Z","shell.execute_reply":"2022-12-12T07:54:37.512193Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = spark.createDataFrame(data_train)\ntest = spark.createDataFrame(data_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:54:38.588829Z","iopub.execute_input":"2022-12-12T07:54:38.589346Z","iopub.status.idle":"2022-12-12T07:54:56.255163Z","shell.execute_reply.started":"2022-12-12T07:54:38.589300Z","shell.execute_reply":"2022-12-12T07:54:56.254153Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"out_cols = [i for i in train.columns if i not in [\"id\", \"comment_text\"]]","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:54:56.257571Z","iopub.execute_input":"2022-12-12T07:54:56.257982Z","iopub.status.idle":"2022-12-12T07:54:56.263067Z","shell.execute_reply.started":"2022-12-12T07:54:56.257947Z","shell.execute_reply":"2022-12-12T07:54:56.262120Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\ntrain_w = tokenizer.transform(train)\ntest_w = tokenizer.transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T07:56:02.848718Z","iopub.execute_input":"2022-12-12T07:56:02.849140Z","iopub.status.idle":"2022-12-12T07:56:03.440770Z","shell.execute_reply.started":"2022-12-12T07:56:02.849098Z","shell.execute_reply":"2022-12-12T07:56:03.439776Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_test_idf(features: int = 262144):\n    global train_w, test_w\n    outp = {}\n    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures = features)\n    train_h = hashingTF.transform(train_w)\n    test_h = hashingTF.transform(test_w)\n    \n    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n    idfModel = idf.fit(train_h) \n    Train = idfModel.transform(train_h)\n    Test = idfModel.transform(test_h)\n    \n    for i in out_cols:\n        obj_model = LogisticRegression(featuresCol=\"features\", labelCol=i, maxIter = 50)\n        model = obj_model.fit(Train)\n        res = model.transform(Test)\n        evaluator = BinaryClassificationEvaluator( labelCol=i)\n        outp[i] = evaluator.evaluate(res)\n    return outp","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:09:39.485672Z","iopub.execute_input":"2022-12-12T08:09:39.486093Z","iopub.status.idle":"2022-12-12T08:09:39.495259Z","shell.execute_reply.started":"2022-12-12T08:09:39.486061Z","shell.execute_reply":"2022-12-12T08:09:39.494243Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"res = {}\nfor i in [500,1000, 2000]:\n    res[i] = train_test_idf(i)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:09:43.314165Z","iopub.execute_input":"2022-12-12T08:09:43.314582Z","iopub.status.idle":"2022-12-12T08:16:28.655703Z","shell.execute_reply.started":"2022-12-12T08:09:43.314548Z","shell.execute_reply":"2022-12-12T08:16:28.654310Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"for i, j in res.items():\n    print(\"numFeatures = \", i)\n    for k, l in j.items():\n        print(\"\\t\" + k + \" = \", l)\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:16:28.658006Z","iopub.execute_input":"2022-12-12T08:16:28.658520Z","iopub.status.idle":"2022-12-12T08:16:28.668657Z","shell.execute_reply.started":"2022-12-12T08:16:28.658465Z","shell.execute_reply":"2022-12-12T08:16:28.667418Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"numFeatures =  500\n\ttoxic =  0.8577864971383122\n\tsevere_toxic =  0.9049685880855972\n\tobscene =  0.8843409207517552\n\tthreat =  0.8882936858813885\n\tinsult =  0.8840253232513319\n\tidentity_hate =  0.8283828449488723\n\nnumFeatures =  1000\n\ttoxic =  0.8751613615001697\n\tsevere_toxic =  0.9021997066359719\n\tobscene =  0.8931503878701298\n\tthreat =  0.8774360012357657\n\tinsult =  0.890487154001317\n\tidentity_hate =  0.8297505009502917\n\nnumFeatures =  2000\n\ttoxic =  0.8900541918847275\n\tsevere_toxic =  0.8938842688842703\n\tobscene =  0.8997107206891362\n\tthreat =  0.8557841246844003\n\tinsult =  0.9014479775180567\n\tidentity_hate =  0.8294840380295881\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Можно заметить, что при увеличении numFeatures качество становится лучше. Это связано с тем, что больше информации извлекается из текста.","metadata":{}},{"cell_type":"code","source":"def get_res_w2v():\n    outp = {}\n    global train_w, test_w\n    word2Vec = Word2Vec(inputCol=\"words\", outputCol=\"w2v_features\")\n    model = word2Vec.fit(train_w)\n    Train = model.transform(train_w)\n    Test = model.transform(test_w)\n    \n    for i in out_cols:\n        obj_model = LogisticRegression(featuresCol=\"w2v_features\", labelCol=i, maxIter = 50)\n        model = obj_model.fit(Train)\n        res = model.transform(Test)\n        evaluator = BinaryClassificationEvaluator( labelCol=i)\n        outp[i] = evaluator.evaluate(res)\n    return outp","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:16:28.670582Z","iopub.execute_input":"2022-12-12T08:16:28.671486Z","iopub.status.idle":"2022-12-12T08:16:28.682021Z","shell.execute_reply.started":"2022-12-12T08:16:28.671420Z","shell.execute_reply":"2022-12-12T08:16:28.680510Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"res = get_res_w2v()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:16:28.685060Z","iopub.execute_input":"2022-12-12T08:16:28.686009Z","iopub.status.idle":"2022-12-12T08:24:04.866251Z","shell.execute_reply.started":"2022-12-12T08:16:28.685961Z","shell.execute_reply":"2022-12-12T08:24:04.865401Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"for i, j in res.items():\n        print(i + \" = \", j)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T08:24:18.094417Z","iopub.execute_input":"2022-12-12T08:24:18.094874Z","iopub.status.idle":"2022-12-12T08:24:18.101220Z","shell.execute_reply.started":"2022-12-12T08:24:18.094833Z","shell.execute_reply":"2022-12-12T08:24:18.099874Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"toxic =  0.9417544215801974\nsevere_toxic =  0.9663468418795814\nobscene =  0.9504943789609587\nthreat =  0.9611918737815482\ninsult =  0.9493444513444956\nidentity_hate =  0.9308283200905938\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Результаты Word2Vec лучше, чем у IDF, это связано с тем, что Word2Vec - более сложная модель, которая лучше отображает контекст сообщений.","metadata":{}}]}